import os
import statistics as st
import sys


#https://www.nature.com/articles/s41598-019-51459-4
perror_cutoff = 0.001    #limit for Perror value (umivar, Perror)
SB_p_cutoff = 0.05      #limit for SB p value (VarDict, SBF)                                                                                    previously 0.001
mean_qual_cutoff = 13   #limit for mean quality score (VarDict, QUAL)       #https://www.drive5.com/usearch/manual/quality_score.html           previously 20
mean_map_cutoff = 13    #limit for mean mapping quality (VarDict, MQ)                                                                           previously 20
SN_cutoff = 8           #limit for signal-to-noise ratio (VarDict, SN) -------> currently not filtering!
SB_phred_cutoff = 30    #limit for Phred-scaled SB value (lofreq, SB)

#accepts a single VCF line/entry and decides based on different errors/values if the entry should be considered or discarded
#True: Entry can be used, False: Entry has to be discarded
def filter_entry(line, source):
    if source == "umivar":
        fil, form, vals = line[6], line[8], line[9]
        if form.split(":")[-1] == "Perror":             #check p error
            perror = float(vals.split(":")[-1])
            if perror < perror_cutoff:
                return False
        if any(e in fil for e in ["Error", "Low_AC", "Low_qual_pos", "Fisher_Strand"]):
            return False
    elif source == "vardict":
        info = line[7].split(";")
        for i in info:
            if "QUAL=" in i:                            #check quality score
                qual = float(i.split("QUAL=")[1])
                if qual < mean_qual_cutoff:
                    return False
            elif "SBF=" in i:                           #check strand bias ( https://www.biostars.org/p/58173/ )
                sbf = float(i.split("SBF=")[1])
                if sbf < SB_p_cutoff:
                    return False
            elif "MQ=" in i:                            #check mapping quality
                mq = float(i.split("MQ=")[1])
                if mq < mean_map_cutoff:
                    return False
            elif "SN=" in i:                            #check signal-to-noise ratio
                sn = float(i.split("SN=")[1])
                if sn < SN_cutoff:
                    return False
    elif source == "lofreq":
        info = line[7]
        if "SB=" in info:                               #check strand bias
            sb = int(info.split("SB=")[1].split(";")[0])
            if sb > SB_phred_cutoff:
                return False
    return True

#reads a single VCF line, returning the called variant and its AF or marking it as filtered
def read_vcf_line(line, source, bed=False, filtering=False):
    if line.startswith("#"):
        sys.exit("Got a line with # at the start; exiting...")
    else:
        line = line.split("\t")
        chrom, pos, ref, alt = line[0], line[1], line[3], line[4]
        if chrom.startswith("chr"):
            chrom = chrom[3:]
            key = "_".join([chrom, pos, ref, alt]) #key is formed from chromosome number, pos, ref base, alt base
            if bed:
                for bline in bed:
                    b = bline.split()
                    if b[0].startswith("chr"):
                        if chrom == b[0][3:] and (int(b[1]) <= int(pos) <= int(b[2])):
                            break
                else:
                    return key, "filter"
        if source in ["lofreq", "vardict"]:
            info = line[7].split(";")
            allele_freq = next(x for x in info if x.startswith('AF='))[3:]
        elif source == "mySimuPipeline":                #VCF was generated by simulation pipeline
            if line[8].endswith("AF"):
                allele_freq = line[9].split(":")[1]
            else:
                sys.exit("Could not obtain allele frequency for simulation; exiting...")
        elif source == "umivar":
            info = line[9].split(":")
            if line[8].split(":")[6] == "M_AF":         #use Multi-UMI alternative allele fraction instead of normal AF
                allele_freq = info[6]
            else:
                sys.exit("Could not obtain allele frequency for umiVar variant caller; exiting...")
        if not filtering or filter_entry(line, source):
            return key, float(allele_freq)              #variant is good to use
        elif filtering and not filter_entry(line, source):
            return key, "filter"                        #variant needs to be ignored

#analyzes all files in the list and creates a dict of the contained variants
def read_files(files, bed=False, filtering=False, maximum=False, remove=False):
    source, fsource = None, None
    var_dict = {}
    if bed:
        with open(bed, "r") as b:
            bed = b.read().splitlines()
    for i, file in enumerate(files):
        file_name = os.path.abspath(file)
        with open(file, "r") as f:
            flines = f.read().splitlines()
        for fl in flines:
            if fl.startswith("##source"):               #pick the VarCaller that was used
                source = ("lofreq" if "lofreq" in fl else "vardict" if "VarDict" in fl else "umivar" if "umiVar" in fl \
                            else "mySimuPipeline" if "mySimuPipeline" in fl else False)
                if source == False:
                    sys.exit("Unknown source, exiting...")
                if isinstance(fsource, str) and isinstance(source, str) and source != fsource:
                    warnings.warn("Input files from different variant callers, exiting...", stacklevel=2)
                if fsource == None:
                    fsource = source
            if not fl.startswith("#"):
                if source == None:
                    sys.exit("Could not determine source, exiting...")
                key, value = read_vcf_line(fl, fsource, bed, filtering)
                if value == "filter":                       #check if variant must be filtered
                    var_dict[key] = "filter"
                else:
                    if not maximum or value <= maximum:
                        if key not in var_dict.keys():
                            var_dict[key] = [0]*len(files)  #set zeros for this variant in each sample
                        if var_dict[key] != "filter":
                            var_dict[key][i] = value        #if variant can be used, replace this zero with the value
                    elif maximum and value > maximum:       #filters variants below the given maximum AF
                        var_dict[key] = "filter"
    var_dict = {k: v for k, v in var_dict.items() if v != "filter"} #remove all filtered variants
    var_dict = {k: v for k, v in var_dict.items() if not all(val == 0 for val in v)}    #remove all variants that were not detected (i.e. only 0s)
    if remove:
        var_dict = {k: v for k, v in var_dict.items() if v[0] != 0} #remove all variants that were not present in the first sample
    return var_dict, source

#calculates the list of medians for a var_dict
def get_median(var_dict):
    median_dict = {}
    for i in range(len(next(iter(var_dict.values())))):  #iterate over time points
        for k in var_dict.keys():                        #iterate over variants
            if i not in median_dict.keys():
                median_dict[i] = []
            median_dict[i].append(var_dict[k][i])
    return [st.median(l) for l in median_dict.values()]  #return list of medians